{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "white    4898\nred      1599\nName: Label, dtype: int64"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# dataset_red=pd.read_csv(\"Data/winequality-red.csv\",sep=\";\",index_col=False)\n",
    "# dataset_white=pd.read_csv(\"Data/winequality-white.csv\",sep=\";\",index_col=False)\n",
    "dataset_red=pd.read_csv(\"C:/Users/10253/Desktop/Machine-Learning-Project-Group-6/Code/Data/winequality-red.csv\",sep=\";\",index_col=False)\n",
    "dataset_white=pd.read_csv(\"C:/Users/10253/Desktop/Machine-Learning-Project-Group-6/Code/Data/winequality-white.csv\",sep=\";\",index_col=False)\n",
    "\n",
    "red=[\"red\"]*len(dataset_red)\n",
    "dataset_red.insert(0,\"Label\",red)\n",
    "white=[\"white\"]*len(dataset_white)\n",
    "dataset_white.insert(0,\"Label\",white)\n",
    "# dataset_white = dataset_white[:1599]\n",
    "# dataset_white.head(n=5)\n",
    "dataset=pd.concat([dataset_red,dataset_white],axis=0)\n",
    "dataset.set_index(\"Label\")\n",
    "\n",
    "X=dataset.drop(\"Label\",axis=1)\n",
    "dataset['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "dataset[\"Label\"]=le.fit_transform(dataset[\"Label\"])\n",
    "y=dataset[\"Label\"]\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "Xs_train,Xs_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=1,stratify=y)\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "norm = Normalizer()\n",
    "Xs_train=norm.fit_transform(Xs_train)\n",
    "Xs_test=norm.transform(Xs_test)\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest,f_classif\n",
    "select = SelectKBest(f_classif, k=4)\n",
    "Xs_train=select.fit_transform(Xs_train,y_train)\n",
    "Xs_test=select.transform(Xs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9782960857464321\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_fs_cv=DecisionTreeClassifier(criterion=\"entropy\")\n",
    "\n",
    "\n",
    "\n",
    "p_grid={\"splitter\":[\"best\",\"random\"],\"max_features\":[1,2,3,4],\"max_depth\":[2,3,4,5,6,7,8]}\n",
    "\n",
    "\n",
    "inner_cv=KFold(n_splits=3,shuffle=True)\n",
    "outer_cv=KFold(n_splits=5,shuffle=True)\n",
    "\n",
    "\n",
    "clf = GridSearchCV(estimator=clf_fs_cv, param_grid=p_grid, cv=inner_cv)\n",
    "nested_score = cross_val_score(clf, X=X, y=y, cv=outer_cv)\n",
    "\n",
    "print(nested_score.mean())\n",
    "# print(y)\n",
    "\n",
    "# clf_fs_cv.fit(Xs_train,y_train)\n",
    "# confusion_matrix(clf_fs_cv.predict(Xs_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 256)               1280      \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 198,913\n",
      "Trainable params: 198,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "130/143 [==========================>...] - ETA: 0s - loss: 0.2721 - accuracy: 0.9255WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.2629 - accuracy: 0.9274 - val_loss: 0.1957 - val_accuracy: 0.9282\n",
      "Epoch 2/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2023 - accuracy: 0.9316 - val_loss: 0.2176 - val_accuracy: 0.9185\n",
      "Epoch 3/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1953 - accuracy: 0.9327 - val_loss: 0.1984 - val_accuracy: 0.9303\n",
      "Epoch 4/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1950 - accuracy: 0.9340 - val_loss: 0.1999 - val_accuracy: 0.9292\n",
      "Epoch 5/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1994 - accuracy: 0.9292 - val_loss: 0.2007 - val_accuracy: 0.9308\n",
      "Epoch 6/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1877 - accuracy: 0.9367 - val_loss: 0.2191 - val_accuracy: 0.9262\n",
      "Epoch 7/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1872 - accuracy: 0.9325 - val_loss: 0.1951 - val_accuracy: 0.9251\n",
      "Epoch 8/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.1936 - accuracy: 0.9316 - val_loss: 0.1905 - val_accuracy: 0.9287\n",
      "Epoch 9/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1835 - accuracy: 0.9362 - val_loss: 0.2027 - val_accuracy: 0.9262\n",
      "Epoch 10/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1810 - accuracy: 0.9375 - val_loss: 0.1866 - val_accuracy: 0.9318\n",
      "Epoch 11/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1785 - accuracy: 0.9382 - val_loss: 0.1836 - val_accuracy: 0.9287\n",
      "Epoch 12/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1804 - accuracy: 0.9371 - val_loss: 0.1816 - val_accuracy: 0.9333\n",
      "Epoch 13/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1803 - accuracy: 0.9349 - val_loss: 0.1840 - val_accuracy: 0.9333\n",
      "Epoch 14/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1758 - accuracy: 0.9373 - val_loss: 0.1946 - val_accuracy: 0.9303\n",
      "Epoch 15/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1780 - accuracy: 0.9364 - val_loss: 0.2042 - val_accuracy: 0.9210\n",
      "Epoch 16/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1743 - accuracy: 0.9353 - val_loss: 0.2021 - val_accuracy: 0.9287\n",
      "Epoch 17/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1814 - accuracy: 0.9364 - val_loss: 0.2048 - val_accuracy: 0.9164\n",
      "Epoch 18/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1760 - accuracy: 0.9375 - val_loss: 0.1788 - val_accuracy: 0.9395\n",
      "Epoch 19/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1745 - accuracy: 0.9397 - val_loss: 0.1749 - val_accuracy: 0.9349\n",
      "Epoch 20/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1737 - accuracy: 0.9404 - val_loss: 0.1772 - val_accuracy: 0.9323\n",
      "Epoch 21/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1716 - accuracy: 0.9378 - val_loss: 0.1767 - val_accuracy: 0.9390\n",
      "Epoch 22/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1705 - accuracy: 0.9364 - val_loss: 0.1888 - val_accuracy: 0.9395\n",
      "Epoch 23/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1730 - accuracy: 0.9384 - val_loss: 0.1878 - val_accuracy: 0.9344\n",
      "Epoch 24/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1672 - accuracy: 0.9402 - val_loss: 0.1662 - val_accuracy: 0.9379\n",
      "Epoch 25/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1627 - accuracy: 0.9413 - val_loss: 0.1699 - val_accuracy: 0.9436\n",
      "Epoch 26/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1645 - accuracy: 0.9415 - val_loss: 0.1664 - val_accuracy: 0.9369\n",
      "Epoch 27/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1618 - accuracy: 0.9411 - val_loss: 0.1735 - val_accuracy: 0.9303\n",
      "Epoch 28/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1663 - accuracy: 0.9411 - val_loss: 0.1708 - val_accuracy: 0.9297\n",
      "Epoch 29/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1612 - accuracy: 0.9419 - val_loss: 0.1697 - val_accuracy: 0.9364\n",
      "Epoch 30/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1640 - accuracy: 0.9411 - val_loss: 0.1574 - val_accuracy: 0.9400\n",
      "Epoch 31/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1595 - accuracy: 0.9415 - val_loss: 0.1564 - val_accuracy: 0.9431\n",
      "Epoch 32/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1545 - accuracy: 0.9441 - val_loss: 0.1558 - val_accuracy: 0.9415\n",
      "Epoch 33/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1518 - accuracy: 0.9470 - val_loss: 0.2455 - val_accuracy: 0.9108\n",
      "Epoch 34/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1735 - accuracy: 0.9415 - val_loss: 0.1616 - val_accuracy: 0.9415\n",
      "Epoch 35/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1654 - accuracy: 0.9364 - val_loss: 0.1805 - val_accuracy: 0.9431\n",
      "Epoch 36/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1638 - accuracy: 0.9419 - val_loss: 0.1551 - val_accuracy: 0.9446\n",
      "Epoch 37/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1552 - accuracy: 0.9461 - val_loss: 0.1640 - val_accuracy: 0.9400\n",
      "Epoch 38/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1596 - accuracy: 0.9426 - val_loss: 0.1571 - val_accuracy: 0.9400\n",
      "Epoch 39/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1536 - accuracy: 0.9463 - val_loss: 0.1628 - val_accuracy: 0.9446\n",
      "Epoch 40/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1583 - accuracy: 0.9422 - val_loss: 0.1555 - val_accuracy: 0.9456\n",
      "Epoch 41/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1534 - accuracy: 0.9455 - val_loss: 0.1861 - val_accuracy: 0.9267\n",
      "Epoch 42/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1548 - accuracy: 0.9424 - val_loss: 0.1563 - val_accuracy: 0.9431\n",
      "Epoch 43/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1547 - accuracy: 0.9433 - val_loss: 0.1607 - val_accuracy: 0.9426\n",
      "Epoch 44/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1525 - accuracy: 0.9483 - val_loss: 0.1701 - val_accuracy: 0.9446\n",
      "Epoch 45/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1520 - accuracy: 0.9466 - val_loss: 0.1813 - val_accuracy: 0.9333\n",
      "Epoch 46/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1521 - accuracy: 0.9452 - val_loss: 0.1513 - val_accuracy: 0.9426\n",
      "Epoch 47/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1524 - accuracy: 0.9437 - val_loss: 0.1646 - val_accuracy: 0.9390\n",
      "Epoch 48/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1508 - accuracy: 0.9492 - val_loss: 0.1535 - val_accuracy: 0.9451\n",
      "Epoch 49/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.9437 - val_loss: 0.1605 - val_accuracy: 0.9400\n",
      "Epoch 50/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1527 - accuracy: 0.9433 - val_loss: 0.1632 - val_accuracy: 0.9400\n",
      "Epoch 51/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1502 - accuracy: 0.9483 - val_loss: 0.1523 - val_accuracy: 0.9441\n",
      "Epoch 52/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1493 - accuracy: 0.9463 - val_loss: 0.1499 - val_accuracy: 0.9462\n",
      "Epoch 53/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.1502 - accuracy: 0.9452 - val_loss: 0.1539 - val_accuracy: 0.9436\n",
      "Epoch 54/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1569 - accuracy: 0.9437 - val_loss: 0.1601 - val_accuracy: 0.9487\n",
      "Epoch 55/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1491 - accuracy: 0.9479 - val_loss: 0.1603 - val_accuracy: 0.9451\n",
      "Epoch 56/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1477 - accuracy: 0.9501 - val_loss: 0.1585 - val_accuracy: 0.9446\n",
      "Epoch 57/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.1498 - accuracy: 0.9470 - val_loss: 0.1807 - val_accuracy: 0.9405\n",
      "Epoch 58/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1564 - accuracy: 0.9459 - val_loss: 0.1535 - val_accuracy: 0.9462\n",
      "Epoch 59/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1473 - accuracy: 0.9474 - val_loss: 0.1551 - val_accuracy: 0.9436\n",
      "Epoch 60/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1495 - accuracy: 0.9468 - val_loss: 0.1848 - val_accuracy: 0.9338\n",
      "Epoch 61/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.1493 - accuracy: 0.9463 - val_loss: 0.1481 - val_accuracy: 0.9477\n",
      "Epoch 62/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1533 - accuracy: 0.9437 - val_loss: 0.1641 - val_accuracy: 0.9477\n",
      "Epoch 63/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1469 - accuracy: 0.9492 - val_loss: 0.1498 - val_accuracy: 0.9451\n",
      "Epoch 64/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1517 - accuracy: 0.9446 - val_loss: 0.1656 - val_accuracy: 0.9431\n",
      "Epoch 65/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.1461 - accuracy: 0.9496 - val_loss: 0.1788 - val_accuracy: 0.9313\n",
      "Epoch 66/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1458 - accuracy: 0.9492 - val_loss: 0.1634 - val_accuracy: 0.9385\n",
      "Epoch 67/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1486 - accuracy: 0.9466 - val_loss: 0.1637 - val_accuracy: 0.9415\n",
      "Epoch 68/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1540 - accuracy: 0.9448 - val_loss: 0.1577 - val_accuracy: 0.9451\n",
      "Epoch 69/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.1522 - accuracy: 0.9439 - val_loss: 0.1507 - val_accuracy: 0.9436\n",
      "Epoch 70/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1438 - accuracy: 0.9492 - val_loss: 0.1460 - val_accuracy: 0.9472\n",
      "Epoch 71/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1466 - accuracy: 0.9477 - val_loss: 0.1707 - val_accuracy: 0.9421\n",
      "Epoch 72/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1442 - accuracy: 0.9485 - val_loss: 0.1576 - val_accuracy: 0.9467\n",
      "Epoch 73/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.1480 - accuracy: 0.9479 - val_loss: 0.1470 - val_accuracy: 0.9462\n",
      "Epoch 74/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1462 - accuracy: 0.9492 - val_loss: 0.1459 - val_accuracy: 0.9472\n",
      "Epoch 75/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1453 - accuracy: 0.9488 - val_loss: 0.1549 - val_accuracy: 0.9487\n",
      "Epoch 76/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1445 - accuracy: 0.9499 - val_loss: 0.1573 - val_accuracy: 0.9431\n",
      "Epoch 77/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.1470 - accuracy: 0.9505 - val_loss: 0.1506 - val_accuracy: 0.9477\n",
      "Epoch 78/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.1443 - accuracy: 0.9514 - val_loss: 0.1547 - val_accuracy: 0.9462\n",
      "Epoch 79/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1503 - accuracy: 0.9444 - val_loss: 0.1596 - val_accuracy: 0.9477\n",
      "Epoch 80/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.1515 - accuracy: 0.9470 - val_loss: 0.1473 - val_accuracy: 0.9462\n",
      "Epoch 81/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.1470 - accuracy: 0.9468 - val_loss: 0.1509 - val_accuracy: 0.9462\n",
      "Epoch 82/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.1499 - accuracy: 0.9472 - val_loss: 0.1658 - val_accuracy: 0.9441\n",
      "Epoch 83/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1476 - accuracy: 0.9472 - val_loss: 0.1535 - val_accuracy: 0.9456\n",
      "Epoch 84/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.1522 - accuracy: 0.9466 - val_loss: 0.1440 - val_accuracy: 0.9472\n",
      "Epoch 85/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1501 - accuracy: 0.9463 - val_loss: 0.1695 - val_accuracy: 0.9364\n",
      "Epoch 86/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1522 - accuracy: 0.9477 - val_loss: 0.1487 - val_accuracy: 0.9472\n",
      "Epoch 87/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1467 - accuracy: 0.9474 - val_loss: 0.1481 - val_accuracy: 0.9451\n",
      "Epoch 88/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9479 - val_loss: 0.1627 - val_accuracy: 0.9492\n",
      "Epoch 89/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.1488 - accuracy: 0.9481 - val_loss: 0.1467 - val_accuracy: 0.9467\n",
      "Epoch 90/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1441 - accuracy: 0.9501 - val_loss: 0.1499 - val_accuracy: 0.9477\n",
      "Epoch 91/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1472 - accuracy: 0.9470 - val_loss: 0.1477 - val_accuracy: 0.9477\n",
      "Epoch 92/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.1426 - accuracy: 0.9503 - val_loss: 0.1518 - val_accuracy: 0.9462\n",
      "Epoch 93/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1441 - accuracy: 0.9492 - val_loss: 0.1546 - val_accuracy: 0.9477\n",
      "Epoch 94/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1417 - accuracy: 0.9483 - val_loss: 0.1423 - val_accuracy: 0.9477\n",
      "Epoch 95/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1457 - accuracy: 0.9479 - val_loss: 0.1444 - val_accuracy: 0.9492\n",
      "Epoch 96/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9477 - val_loss: 0.1499 - val_accuracy: 0.9462\n",
      "Epoch 97/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1465 - accuracy: 0.9488 - val_loss: 0.1520 - val_accuracy: 0.9431\n",
      "Epoch 98/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1427 - accuracy: 0.9492 - val_loss: 0.1585 - val_accuracy: 0.9441\n",
      "Epoch 99/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.1419 - accuracy: 0.9507 - val_loss: 0.1451 - val_accuracy: 0.9462\n",
      "Epoch 100/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.1412 - accuracy: 0.9488 - val_loss: 0.1549 - val_accuracy: 0.9451\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x29152f4cd30>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "#NN model\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(256, input_dim=4, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(256, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(256, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(256, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(np.array(Xs_train), np.array(y_train), epochs=100, validation_data=(np.array(Xs_test), np.array(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      "3199    1\n",
      "3547    1\n",
      "4503    1\n",
      "510     1\n",
      "3413    1\n",
      "       ..\n",
      "1054    0\n",
      "24      1\n",
      "567     1\n",
      "3575    1\n",
      "618     0\n",
      "Name: Label, Length: 1950, dtype: int32\n",
      "[[ 419   61]\n",
      " [  46 1424]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.9451282051282052"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "y_pred = model.predict_classes(Xs_test)\n",
    "print(y_pred)\n",
    "print(y_test)\n",
    "y_test = np.array(y_test)\n",
    "y_test = y_test.reshape(y_test.shape[0], 1)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('mle_tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "de28e1e25f48b68b9638a29c8142fb7816a4ec90feebba1cd15c63ff7df4d74f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
