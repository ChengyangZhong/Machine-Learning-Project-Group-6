{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# dataset_red=pd.read_csv(\"Data/winequality-red.csv\",sep=\";\",index_col=False)\n",
    "# dataset_white=pd.read_csv(\"Data/winequality-white.csv\",sep=\";\",index_col=False)\n",
    "dataset_red=pd.read_csv(\"C:/Users/10253/Desktop/Machine-Learning-Project-Group-6/Data/winequality-red.csv\",sep=\";\",index_col=False)\n",
    "dataset_white=pd.read_csv(\"C:/Users/10253/Desktop/Machine-Learning-Project-Group-6/Data/winequality-white.csv\",sep=\";\",index_col=False)\n",
    "\n",
    "red=[\"red\"]*len(dataset_red)\n",
    "dataset_red.insert(0,\"Label\",red)\n",
    "white=[\"white\"]*len(dataset_white)\n",
    "dataset_white.insert(0,\"Label\",white)\n",
    "# dataset_white.head(n=5)\n",
    "dataset=pd.concat([dataset_red,dataset_white],axis=0)\n",
    "dataset.set_index(\"Label\")\n",
    "\n",
    "X=dataset.drop(\"Label\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "Xs=scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "dataset[\"Label\"]=le.fit_transform(dataset[\"Label\"])\n",
    "y=dataset[\"Label\"]\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest,f_classif\n",
    "Xs=SelectKBest(f_classif,k=4).fit_transform(Xs,y)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "Xs_train,Xs_test,y_train,y_test=train_test_split(Xs,y,test_size=0.3,random_state=1,stratify=y)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9844540771007283\n",
      "0         red\n",
      "1         red\n",
      "2         red\n",
      "3         red\n",
      "4         red\n",
      "        ...  \n",
      "4893    white\n",
      "4894    white\n",
      "4895    white\n",
      "4896    white\n",
      "4897    white\n",
      "Name: Label, Length: 6497, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[ 465,   14],\n       [  15, 1456]], dtype=int64)"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_fs_cv=DecisionTreeClassifier(criterion=\"entropy\")\n",
    "\n",
    "\n",
    "\n",
    "p_grid={\"splitter\":[\"best\",\"random\"],\"max_features\":[1,2,3,4],\"max_depth\":[2,3,4,5,6,7,8]}\n",
    "\n",
    "\n",
    "inner_cv=KFold(n_splits=3,shuffle=True)\n",
    "outer_cv=KFold(n_splits=5,shuffle=True)\n",
    "\n",
    "\n",
    "clf = GridSearchCV(estimator=clf_fs_cv, param_grid=p_grid, cv=inner_cv)\n",
    "nested_score = cross_val_score(clf, X=Xs, y=y, cv=outer_cv)\n",
    "\n",
    "print(nested_score.mean())\n",
    "print(y)\n",
    "\n",
    "clf_fs_cv.fit(Xs_train,y_train)\n",
    "confusion_matrix(clf_fs_cv.predict(Xs_test),y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 256)               1280      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 198,913\n",
      "Trainable params: 198,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.0857 - accuracy: 0.9791 - val_loss: 0.0478 - val_accuracy: 0.9882\n",
      "Epoch 2/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0370 - accuracy: 0.9908 - val_loss: 0.0474 - val_accuracy: 0.9892\n",
      "Epoch 3/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0347 - accuracy: 0.9901 - val_loss: 0.0669 - val_accuracy: 0.9872\n",
      "Epoch 4/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0419 - accuracy: 0.9890 - val_loss: 0.0513 - val_accuracy: 0.9892\n",
      "Epoch 5/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0321 - accuracy: 0.9910 - val_loss: 0.0530 - val_accuracy: 0.9882\n",
      "Epoch 6/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0309 - accuracy: 0.9910 - val_loss: 0.0462 - val_accuracy: 0.9897\n",
      "Epoch 7/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0299 - accuracy: 0.9905 - val_loss: 0.0569 - val_accuracy: 0.9892\n",
      "Epoch 8/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0296 - accuracy: 0.9925 - val_loss: 0.0533 - val_accuracy: 0.9897\n",
      "Epoch 9/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0296 - accuracy: 0.9908 - val_loss: 0.0566 - val_accuracy: 0.9897\n",
      "Epoch 10/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0299 - accuracy: 0.9905 - val_loss: 0.0530 - val_accuracy: 0.9887\n",
      "Epoch 11/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0300 - accuracy: 0.9921 - val_loss: 0.0535 - val_accuracy: 0.9897\n",
      "Epoch 12/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0273 - accuracy: 0.9914 - val_loss: 0.0551 - val_accuracy: 0.9897\n",
      "Epoch 13/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0275 - accuracy: 0.9925 - val_loss: 0.0469 - val_accuracy: 0.9897\n",
      "Epoch 14/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0265 - accuracy: 0.9916 - val_loss: 0.0596 - val_accuracy: 0.9903\n",
      "Epoch 15/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0267 - accuracy: 0.9932 - val_loss: 0.0521 - val_accuracy: 0.9892\n",
      "Epoch 16/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0266 - accuracy: 0.9919 - val_loss: 0.0527 - val_accuracy: 0.9882\n",
      "Epoch 17/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0250 - accuracy: 0.9925 - val_loss: 0.0566 - val_accuracy: 0.9882\n",
      "Epoch 18/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0247 - accuracy: 0.9919 - val_loss: 0.0601 - val_accuracy: 0.9897\n",
      "Epoch 19/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0286 - accuracy: 0.9908 - val_loss: 0.0525 - val_accuracy: 0.9867\n",
      "Epoch 20/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0232 - accuracy: 0.9927 - val_loss: 0.0621 - val_accuracy: 0.9892\n",
      "Epoch 21/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0242 - accuracy: 0.9919 - val_loss: 0.0600 - val_accuracy: 0.9903\n",
      "Epoch 22/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0230 - accuracy: 0.9916 - val_loss: 0.0557 - val_accuracy: 0.9887\n",
      "Epoch 23/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0227 - accuracy: 0.9925 - val_loss: 0.0701 - val_accuracy: 0.9877\n",
      "Epoch 24/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0215 - accuracy: 0.9932 - val_loss: 0.0672 - val_accuracy: 0.9903\n",
      "Epoch 25/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0211 - accuracy: 0.9932 - val_loss: 0.0841 - val_accuracy: 0.9903\n",
      "Epoch 26/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0214 - accuracy: 0.9925 - val_loss: 0.0667 - val_accuracy: 0.9877\n",
      "Epoch 27/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0209 - accuracy: 0.9927 - val_loss: 0.0807 - val_accuracy: 0.9856\n",
      "Epoch 28/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0227 - accuracy: 0.9934 - val_loss: 0.0773 - val_accuracy: 0.9882\n",
      "Epoch 29/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0197 - accuracy: 0.9921 - val_loss: 0.0846 - val_accuracy: 0.9892\n",
      "Epoch 30/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0184 - accuracy: 0.9936 - val_loss: 0.1007 - val_accuracy: 0.9892\n",
      "Epoch 31/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0200 - accuracy: 0.9930 - val_loss: 0.0725 - val_accuracy: 0.9867\n",
      "Epoch 32/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 0.9932 - val_loss: 0.0929 - val_accuracy: 0.9892\n",
      "Epoch 33/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0180 - accuracy: 0.9927 - val_loss: 0.0792 - val_accuracy: 0.9903\n",
      "Epoch 34/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0217 - accuracy: 0.9927 - val_loss: 0.0803 - val_accuracy: 0.9882\n",
      "Epoch 35/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0217 - accuracy: 0.9932 - val_loss: 0.0899 - val_accuracy: 0.9821\n",
      "Epoch 36/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0209 - accuracy: 0.9923 - val_loss: 0.0934 - val_accuracy: 0.9851\n",
      "Epoch 37/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0220 - accuracy: 0.9919 - val_loss: 0.1023 - val_accuracy: 0.9882\n",
      "Epoch 38/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9943 - val_loss: 0.0981 - val_accuracy: 0.9908\n",
      "Epoch 39/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0237 - accuracy: 0.9923 - val_loss: 0.0712 - val_accuracy: 0.9872\n",
      "Epoch 40/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 0.9932 - val_loss: 0.0960 - val_accuracy: 0.9897\n",
      "Epoch 41/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0143 - accuracy: 0.9941 - val_loss: 0.1094 - val_accuracy: 0.9887\n",
      "Epoch 42/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 0.9936 - val_loss: 0.1116 - val_accuracy: 0.9882\n",
      "Epoch 43/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0153 - accuracy: 0.9943 - val_loss: 0.1012 - val_accuracy: 0.9867\n",
      "Epoch 44/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0139 - accuracy: 0.9932 - val_loss: 0.1228 - val_accuracy: 0.9882\n",
      "Epoch 45/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0121 - accuracy: 0.9956 - val_loss: 0.1183 - val_accuracy: 0.9872\n",
      "Epoch 46/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.9949 - val_loss: 0.1127 - val_accuracy: 0.9892\n",
      "Epoch 47/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0137 - accuracy: 0.9930 - val_loss: 0.1251 - val_accuracy: 0.9851\n",
      "Epoch 48/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0121 - accuracy: 0.9945 - val_loss: 0.1246 - val_accuracy: 0.9882\n",
      "Epoch 49/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0173 - accuracy: 0.9938 - val_loss: 0.1040 - val_accuracy: 0.9887\n",
      "Epoch 50/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0156 - accuracy: 0.9945 - val_loss: 0.0914 - val_accuracy: 0.9892\n",
      "Epoch 51/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0135 - accuracy: 0.9952 - val_loss: 0.1058 - val_accuracy: 0.9882\n",
      "Epoch 52/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9947 - val_loss: 0.1120 - val_accuracy: 0.9882\n",
      "Epoch 53/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.9960 - val_loss: 0.1391 - val_accuracy: 0.9872\n",
      "Epoch 54/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0131 - accuracy: 0.9956 - val_loss: 0.1210 - val_accuracy: 0.9872\n",
      "Epoch 55/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0092 - accuracy: 0.9960 - val_loss: 0.1657 - val_accuracy: 0.9867\n",
      "Epoch 56/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0162 - accuracy: 0.9952 - val_loss: 0.1343 - val_accuracy: 0.9877\n",
      "Epoch 57/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 0.9958 - val_loss: 0.1322 - val_accuracy: 0.9872\n",
      "Epoch 58/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 0.9967 - val_loss: 0.1698 - val_accuracy: 0.9851\n",
      "Epoch 59/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 0.9967 - val_loss: 0.1618 - val_accuracy: 0.9872\n",
      "Epoch 60/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0083 - accuracy: 0.9967 - val_loss: 0.1658 - val_accuracy: 0.9862\n",
      "Epoch 61/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.1952 - val_accuracy: 0.9877\n",
      "Epoch 62/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 0.1828 - val_accuracy: 0.9882\n",
      "Epoch 63/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0267 - accuracy: 0.9952 - val_loss: 0.1084 - val_accuracy: 0.9877\n",
      "Epoch 64/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0129 - accuracy: 0.9960 - val_loss: 0.1360 - val_accuracy: 0.9867\n",
      "Epoch 65/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.1477 - val_accuracy: 0.9872\n",
      "Epoch 66/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 0.9967 - val_loss: 0.1617 - val_accuracy: 0.9882\n",
      "Epoch 67/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0091 - accuracy: 0.9967 - val_loss: 0.1522 - val_accuracy: 0.9872\n",
      "Epoch 68/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.1632 - val_accuracy: 0.9877\n",
      "Epoch 69/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 0.9985 - val_loss: 0.1741 - val_accuracy: 0.9872\n",
      "Epoch 70/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 0.9949 - val_loss: 0.1536 - val_accuracy: 0.9836\n",
      "Epoch 71/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0137 - accuracy: 0.9949 - val_loss: 0.1227 - val_accuracy: 0.9862\n",
      "Epoch 72/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 0.1322 - val_accuracy: 0.9867\n",
      "Epoch 73/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.1645 - val_accuracy: 0.9856\n",
      "Epoch 74/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 0.9969 - val_loss: 0.1506 - val_accuracy: 0.9872\n",
      "Epoch 75/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.2071 - val_accuracy: 0.9882\n",
      "Epoch 76/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 0.9965 - val_loss: 0.1723 - val_accuracy: 0.9846\n",
      "Epoch 77/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9956 - val_loss: 0.1825 - val_accuracy: 0.9872\n",
      "Epoch 78/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.1713 - val_accuracy: 0.9872\n",
      "Epoch 79/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 0.9971 - val_loss: 0.1920 - val_accuracy: 0.9882\n",
      "Epoch 80/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.1741 - val_accuracy: 0.9882\n",
      "Epoch 81/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 0.9978 - val_loss: 0.1907 - val_accuracy: 0.9867\n",
      "Epoch 82/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 0.9974 - val_loss: 0.2322 - val_accuracy: 0.9877\n",
      "Epoch 83/100\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.2079 - val_accuracy: 0.9856\n",
      "Epoch 84/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 0.9947 - val_loss: 0.1253 - val_accuracy: 0.9841\n",
      "Epoch 85/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.1506 - val_accuracy: 0.9867\n",
      "Epoch 86/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 0.9971 - val_loss: 0.2022 - val_accuracy: 0.9867\n",
      "Epoch 87/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.2315 - val_accuracy: 0.9887\n",
      "Epoch 88/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.1898 - val_accuracy: 0.9887\n",
      "Epoch 89/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 0.9974 - val_loss: 0.1949 - val_accuracy: 0.9908\n",
      "Epoch 90/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0111 - accuracy: 0.9971 - val_loss: 0.1440 - val_accuracy: 0.9882\n",
      "Epoch 91/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.1632 - val_accuracy: 0.9882\n",
      "Epoch 92/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 0.9980 - val_loss: 0.1906 - val_accuracy: 0.9867\n",
      "Epoch 93/100\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.1558 - val_accuracy: 0.9867\n",
      "Epoch 94/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 0.9971 - val_loss: 0.1723 - val_accuracy: 0.9903\n",
      "Epoch 95/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0125 - accuracy: 0.9967 - val_loss: 0.1334 - val_accuracy: 0.9897\n",
      "Epoch 96/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.9969 - val_loss: 0.1531 - val_accuracy: 0.9887\n",
      "Epoch 97/100\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 0.9985 - val_loss: 0.1760 - val_accuracy: 0.9887\n",
      "Epoch 98/100\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.2089 - val_accuracy: 0.9882\n",
      "Epoch 99/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 0.9982 - val_loss: 0.2326 - val_accuracy: 0.9877\n",
      "Epoch 100/100\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.1968 - val_accuracy: 0.9877\n",
      "[[1]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      "3199    1\n",
      "3547    1\n",
      "4503    1\n",
      "510     1\n",
      "3413    1\n",
      "       ..\n",
      "1054    0\n",
      "24      1\n",
      "567     1\n",
      "3575    1\n",
      "618     0\n",
      "Name: Label, Length: 1950, dtype: int32\n",
      "[[ 464   16]\n",
      " [   8 1462]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.9876923076923076"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "#NN model\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(256, input_dim=4, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(256, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(256, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(256, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(np.array(Xs_train), np.array(y_train), epochs=100, validation_data=(np.array(Xs_test), np.array(y_test)))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "y_pred = model.predict_classes(Xs_test)\n",
    "print(y_pred)\n",
    "print(y_test)\n",
    "y_test = np.array(y_test)\n",
    "y_test = y_test.reshape(y_test.shape[0], 1)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
